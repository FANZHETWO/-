## 对于前端性能优化，你知道的有哪些？

### 对于CSS和HTML
CSS和HTML是否能作为两门语言，可能对于后台开发者来说可能会有点好笑，但是作为一个热爱前端的工作者，我觉得这个作为两门语言一点都不为过，至少他们在浏览器的初期，是静态页面的统领者，当然我们作为天天跟这两门语言打交道的人，也应该尽力去了解他们背后运行的原理，懂得浏览器是怎么识别他们的。了解了他们背后运行的机制后才能写出性能最优的代码。有时候我们知其然却不知所以然，我们知道HTML不能嵌套太深，但是为什么呢？我们知道CSS要尽量不要用标签名作为class类名。要动态插入样式时把所有的样式放到一个class里面要比一个一个style插入好。所以的这些知识点背后都有其存在的理由，下面就由我来带大家解开这个神秘的面纱。

##### CSS渲染的特点
> 加载CSS资源时，浏览器将不会渲染任何已处理的内容，直至CSSOM构建完毕。HTML和CSS都是阻塞渲染的资源。所以优化的空间就是尽早、 尽快的下载都客户端，以便缩短首次渲染的时间。

#### 浏览器是如何渲染的？

##### 首选会通过以下几个步骤
1、处理HTML标记并构建DOM树。
2、处理CSS标记并构建CSSOM树。
3、将DOM与CSSOM合并成一个渲染树。
4、根据渲染树来布局，以计算每个节点的几何信息。
5、将各个节点绘制到屏幕上。

**优化的关键路径就是最大限度缩短执行上述1-5步所要消耗的时间。**

##### HTML、CSS渲染过程的一些特点
1、顺序执行、并发加载
- js词法分析（AST）： 从上到下;能够把这个解析过程了解清楚的，让我来崇拜你把。
- 并发加载 ： 资源并发请求（根据浏览器不同，chrome的最大并发次数好像是6）

2、是否阻塞
- css head 中阻塞页面的渲染,这大家应该都知道。
- css 阻塞js的执行；这个肯定也是阻塞的，虽然是不同的两个线程，但是两边运行都是会影响最后的渲染结果，所以为了正常执行，只能其中一方单独运行。
- css 不阻塞外部脚本的加载。
 **js 阻塞**
- 直接引入的js阻塞页面的渲染（原因：会涉及操作dom）
- js不阻塞资源的加载
- js顺序执行，阻塞后续js逻辑的执行（原理：单线程）

*当然还有其他影响阻塞的因素，比如说依赖关系，可能其中的js运行需要依赖其他的js库，比如说我们通过vue编写的代码就需要先引入vue的库。还有引入方式的不同，是同步还是异步，通过添加defer和async来决定引入的方式。*

3、构建渲染树的过程
(1)、从 DOM树的根节点开始遍历每个可见节点。
- 某些节点不可见（例如脚本标记、元标记），因为它们不会体现在渲染输出中，所以会被忽略。
- 某些节点通过CSS隐藏，因此在渲染树中也会被忽略。**比如要是设置了display:none属性，就不会出现在渲染树中，所以对于不常用的资源可以选择使用这个属性。**
(2)、对于每个可见的节点，为其匹配CSSOM规则并应用它们。
(3)、发射可见节点，连同其内容和计算的样式。

4、visibility:hidden与display:none的区别
前者是隐藏元素，但元素仍占据着布局空间（即将其渲染成一个空旷），而后者将元素从渲染树中完全移除，元素即不可见，也不是布局的组成部分。

5、有了渲染树，接下来就是进入布局阶段（自动重排）

为了弄清每个对象在网页上确切的大小和位置，浏览器从渲染树的根节点开始遍历。布局流程的输出是一个“盒模型”，它会精确地捕获每个元素在窗口内的确切位置和尺寸，即所有相对测量值都转换为屏幕上的绝对像素。
当节点和计算样式等几何信息排列好后，就会执行最后一个阶段，将渲染树中的每个节点转换成屏幕上的实际像素。这一步通常称为“绘制”或“栅格化”

6、渲染的时间长度来源
执行渲染树的构建、布局和绘制所需的时间将取决与文档的大小、应用的样式，以及运行文档的设备：文档越大，浏览器需要完成的工作就越多；样式越复杂，绘制需要的时间就越长（例如。单色的绘制开销就比阴影的计算和渲染开销要小）

7、DOM和CSSOM合并成如下图

  ![render tree](https://developers.google.cn/web/fundamentals/performance/critical-rendering-path/images/render-tree-construction.png)


##### 重绘（Repaint）和回流（Reflow）

###### css性能让javascript变慢？
> 前面已经提到过css是阻塞js执行的，当css频繁的触发重绘与回流，会导致UI频繁渲染，最终阻塞了js的执行。

###### 概念
**回流**
- 当render tree 中的一部分（或全部）因为元素的规模尺寸，布局，隐藏等改变而需要重新构建
  。这就称为回流（reflow）
- 当页面布局和几何属性改变时就需要回流,也称为重排；

**重绘**
- 当render tree 中一些元素需要更新属性，而这些属性只是影响元素的外观，风格，而不会影响布局。比如只改变颜色和背景。这个过程称为重绘。

**区分**
- 回流必会引起重绘，但重绘不一定引起回流。

###### 哪些属性会触发页面重布局
- 盒子模型相关属性会触发重布局
width height padding margin display border-width border min-height
- 定位属性及浮动也会触发重布局
top bottom left right position float clear 
- 改变节点内部文字结构也会触发重布局
  text-align overflow-y font-weight overflow font-family line-height vertival-align white-space font-size

以上属性会影响到页面回流，所以我们在操作css样式时，尽量避免这些属性的改变。

###### CSS优化的两点根本原理
1、 避免使用触发重绘、回流的css属性
2、将重绘、回流的影响范围限制在单独的图层之内

**所以根据上面两点，平时我们的demo中可以做下面优化**

1、用translate代替top改变，因为top会引起回流。
2、用opacity代替visibility，但特别注意的地方，就是opacity要在单独的一个图层
3、不要一条一条的修改DOM样式，预先定义好clas,然后修改DOM的clasName;
4、把DOM离线修改，也就时说通过display:none先影藏节点，修改完后再显示出来。
5、不要把DOM结点的属性值放在一个循环里当成循环的里的变量，比如每当读取offsetHeight,offsetWidth,会强制刷新dom节点的缓存机制，这样会造成性能浪费。
6、不要使用table布局，因为一个小的改动都会造成整个table的重新布局
7、动画实现速度的选择最后跟浏览器的绘制帧数相吻合。也就是可以通过监听requestAnimationFrame等浏览器全局事件来做处理
8、对于动画新建图层，这样新的图层绘制不会影响其他图层。
9、通过启用GPU硬件加速(GPU即图形处理器，是与处理和绘制图形相关的硬件。GPU是专为执行复杂的数学和几何计算而设计的，可以让CPU从图形处理的任务中解放出来，从而执行其他更多的系统任务，例如，页面的计算与重绘).以前开启GPU都是通过 transform: translateZ(0);等hack手法，现在通过will-change:transform;这个属性就能达到同样的效果，但是要注意的是，用完就得抛弃（也就是将值设为will-change:auto），不然会造成资源浪费。

###### 为chrome创建图层的条件
- 3D或透视变换（perspective transform）CSS属性
- 使用加速视频解码的<video> 节点
- 拥有3D（webGL）上下文或加速的2D上下文的<canvas>节点
- 混合插件（如Flash）
- 对自己的opacity做CSS动画或使用一个动画webkit变换的元素
- 拥有加速CSS过滤器的元素
- 元素有一个包含复合层的后代节点（一个元素拥有一个子元素，该子元素在自己的层里）
- 元素有一个z-index较低且包含一个复合层的兄弟元素（即该元素在复合层上面渲染）

###### 优化性能没有强心剂的手段，只有不断的查漏补缺
> 对于CSS和HTML的优化，平时在搬砖的时候就要不断的去思考， 怎么才能写出性能最佳的代码，而不是写完出现问题了再想着怎么去优化。对于资源的优化只有平时的点滴积累，它不会像可以一针治愈的BUG，找到消灭就能够完事。而是要平时不断的思考，了解其背后运行的机制，才能写出最优的代码。

### 对于图片我们能做哪些优化

###### 我的一些感悟

有些项目用到的图片比较多，所以对于图片的优化可能会起到很关键的一环，说的夸张一些，图片要是优化的好，项目至少能优化70%。说句真实的，当我了解不同图片在不同场合的运用，以及怎么压缩优化时，我把项目体积大小优化了一半，这确实震惊到我了，原来图片优化的空间有这么大，同时我又后悔怎么不早点了解图片的这些原理，因为很多项目都已经发版上线，有些优化是做不了的，比如将小图片合并成雪碧图，或者用iconfont字体。或者在切图时就嘱咐UI小姐姐，什么时候用jpg，什么场景用png，现在项目已经上线，再改动可能性不大，除非项目老大给排期派工，哈哈，这估计是不可能的，毕竟我们公司业务逻辑比性能优化跟重要。但是对于我们自己来说，从一开始做一个项目就知道怎么去合理规划和运用那些图片，从一开始就把图片优化做好，这不仅对于我们自己来说是一个技能的提升，对于项目或者对公司来说，也是无形中省了很多流量开销，也就是为公司节省了更多的成本。

### 项目中我们都会遇见哪些图片？他们的优缺点都是什么？

###### png8/png24/png32
- png8 --- 256色+支持透明
- png24 --- 2^24色+不支持透明
- png32 --- 2^24色+支持透明

**优点**
png的优点其实很明显，彩色变现能力最好，无损压缩，能够支持透明，可以处理比较复杂的图像，也是我们UI小姐姐最喜欢用的一种格式。对于8、24、32的区别越大所对象的颜色越多，自然体积也就越大。所以除非有特性较真的场景，一般我们都只用png8就能够满足了。所以如果图片比较复杂、色彩层次比较丰富，又要透明，就使用png8。但是考虑到成本比较大的情况，要是对于页面效果没有那么高的要求，还是建议使用jpg。
**缺点**
缺点其实很明显，那就是体积对比jpg会大很多，所以不管是放到本地，还是服务器，都是要斟酌来考虑的。这里推荐两种压缩图片的工具，可以无损的压缩我们的png图片。[在线网站地址](!https://tinypng.com),还有就是可以使用[webpack的一个图片压缩插件](!https://github.com/tcoopman/image-webpack-loader),但是这个插件使用后打包会比较慢。


###### JPEG/JPG

我们的UI小姐姐不喜欢用这种格式的图片，给出的原因是色彩达不到他们的要求，同时压缩是有损的，当然，JPG最大的特点就是有损压缩，所以压缩后相对与PNG的体积要小很多，如果不是色彩能明显，我们的肉眼一般是分辨不出的，所以这种格式的图片只能找合适他们的场景，由于不支持透明，所以这个场景就不能使用，我们日常常用就是用来作为背景图，对于一些线条感较强，颜色比较强烈的就达不到要求了。

###### SVG

和前面两种格式的图片对比，最明显的优势就是文件体积更小了，而且可压缩性更强。当然我们知道它还有更明显的优势就是图片可以无限放大却不失真，所以对于多个场景的分辨率SVG都能胜任。我们平时用的最多的地方就是用于颜色比较单一的背景图，所以ICON，比如使用了[阿里的矢量图库](!https://www.iconfont.cn/home/index?spm=a313x.7781069.1998910419.2),好用，但可能需要一些成本来管理，特别是对于很对小模块的项目来说，比如说我们项目组，要管理几十个小项目，要是每个小项目都建一个矢量图库来管理其实是很头大的，那么我们平时是怎么来使用小图标的呢？那么接下来有请我们的base64先生吧。

###### base64 & 雪碧图

这是一个神奇的编码，平时工作中可以说随时可见，至于背后运行的原理也不是很难，具体可以看这篇[文章](!http://www.ruanyifeng.com/blog/2008/06/base64.html),其实就是将不同的数据格式通过一个base64编码表来转换。但是对于前端图片这方面它有什么特别之处？雪碧图想必大家都非常熟悉，将多个小图标合并在一起，然后通过定位显示你需要的那一部分，优势就是更少HTTP请求，缓存下来后对于内存和宽带会更友好，但一张雪碧图最好不要太大，不然对于页面的加载会比较慢，大家可以看一些常见的电商网站，基本一张雪碧图基本都是在2M以内。然后base64的也有这么一个优化，我们平时的小图标如果是转成base64，那么通过工具处理后就会将小图标转成base64编码，然后插入到html或css中，这样加载DOM树时，就不必重新请求http了，直接将编码渲染即可。但是base64有一个缺点，那就是小图标转成base64后体积将会膨胀成原文件的4/3左右，这意味着图片越大，转成base64编码也就会越大，我们都知道构建DOM树时对性能的是会消耗的，大量的base64编码会对渲染造成阻塞，所以到底多大的图片适合转成base64,作者阅读了大量资料也没看到一个明确的范围，参考几个大型电商网站的做法，绝大多少都是控制在2M以下，所以我们平时的项目开发中，limit的设置可以参考这个条件。


### 浏览器缓存机制是面试时比较常见的一个考察点，对于这块的知识你又了解多少？

**缓存的意义**
> 网络获取内容会依赖网络环境同时开销巨大。客户端与服务器多次得往返通信，需要浏览器不停的去处理和获得内容，同时也会增加用户的流量费用。因此，缓存并重复利用之前就获取得资源对于性能优化会有很大得帮助。
 

**制定缓存策略**
- 如果要缓存，网址要确保一致
- 确保服务器提供验证令牌（ETag）:有了验证令牌，当服务器资源未发生变化时，就不需要传送相同的字节。
- 确定中间缓存可以缓存哪些资源：对所有用户的响应完全相同的资源非常合适由CDN以及其他中间缓存进行缓存。
- 为每个资源确定最佳缓存周期：不同的资源可能有不同的更新需求，为每个资源审核并确定合适的max-age
- 确定合适你的网站的缓存层次结构。
- 区分资源变动的资源：将频繁变动的资源和不是很频繁的资源区分开来。

*背景*
> 缓存是性能优化中简单高效的优化方式，它可以显著减少网络传输所带来的消耗。


**HTTP缓存**
> 是日常开发中最为熟悉得一种缓存机制。，分为强缓存和协商缓存。强缓存优先级高于协商缓存

- 强缓存
Expires和Cache-Control两个相关字段。
命中强缓存，返回得HTTP状态码为200， 同时你会看到状态码后面会接一个**(from disk cache)或者(from memory cache)**。
```
Expires: Fri, 04 May 2029 11:37:22 GMT
```
我们可以看到Expires是一个时间戳，浏览器只能取到本地时间，如果用本地时间去对比肯定是有问题的，因为我们是可以修改客户端的时间的。所以HTTP1.1新增了**Cache-Control**字段来替代Expires.所以Cache-Control的优先级要高。
```
Cache-Control: max-age=315360000
```
我们可以通过max-age来控制资源得有效期。max-age是一个时间长度，上面即表示315360000秒。当 Cache-Control 与 expires 同时出现时，我们以 Cache-Control 为准。

**Cache-Control的其它值**
*max-age=<seconds>*
> 设置缓存时间，设置单位为秒，本地缓存和共享缓存都可以

*s-maxage*
> s-maxage的优先级高于max-age.主要用于代理服务器中。客户端我们只用max-age就行。并且s-maxage只对public缓存有效。

*public与private得区别*
> 设置为public时，既可以被浏览器缓存，也可以被代理服务器缓存。设置为private时，只能被浏览器缓存，并且private为默认值。

*no-store和no-cache的区别*
>设置了no-cache后，请求时浏览器不会询问缓存得情况，而是直接请求服务器是否该资源过期。
设置了no-store后，不会使用任何缓存策略。连同服务端得缓存策略也绕开了。直接下载最新的资源。

*immutable*
> 表示文档是不能修改的

*must-revalidate*
> 表示客户端必须检测代理服务器上是否存在，即使已经缓存到了本地也要检查

*proxy-revalidate*
> 表示共享缓存（CDN）必须要检测源是否存在，即使已经有缓存

**实例说明**
Cache-Control: public max-age=3600  //本地缓存和CDN缓存1小时
Cache-Control: private immutable //不能缓存在CDN 只能本地缓存 并且一旦被缓存就不能修改
Cache-Control: no-cache  //不能缓存。 如果一定要缓存的话，确保对其进行二次验证
Cache-Control: public max-age=3600 s-maxage=7200 //本地缓存1小时  CDN上缓存两小时
Cache-Control: public max-age=3600 proxy-revalidate 本地和CDN都缓存1小时。但是如果CDN收到请求，则尽管已经缓存了1小时，还是要检测源中文档是否已经被改变

**协商缓存** 
> 通过协商两个字就知道，功能需要协商才能定夺。协商缓存就是依赖于服务端与浏览器之间得通信。协商缓存机制下，浏览器需要向服务器咨询缓存得相关信息，进而判断是重新发起请求、下载完整得响应，还是从本地获取缓存得资源。

**如果服务端提示缓存资源未改动（Not Modified）**资源就会被重定向到浏览器缓存，这时候网络请求对应得状态码是304.

*Last-Modified和Etag*
```
last-modified: Fri, 11 Jan 2019 01:54:59 GMT
```
last-modified也是一个时间戳。通过Response Headers返回。随后的请求，会带上一个叫if-modified-since的时间戳，也就是上一次response返回的lasr-modified值。服务器接受这个时间戳后，会对比该时间戳和资源在服务器上得最后修改时间是否一致，从而判断资源是否发生了变化。如果变化了则会返回最新请求并返回最新的last-modified值。
**使用last-modified的弊端**
1、虽然客户端有改变，但是不想重新请求，而服务端根据时间判断需要重新响应，这样就会达不到效果。
2、如果客户端修改时间比较短，比if-modified-since（只能以秒为单位）返回的时间还要短。则会出现想重新请求却不会请求到的情况。

**Etag**
> 由服务器为每个资源生成得唯一得标识字符串，原理是基于文件内容编码得，只要文件内容不同，对用的值就不一样。
```
etag: W/"5715dcfb-171b"
```
首次请求时，会在响应头里获取一个最初得标识字符串，下一次请求时，请求头就会带上一个**if-None-Match**字符串供服务端对比。

**Etag得弊端**
服务器需要额外得开销来生成Etag,会影响到服务端得性能。Etag在感知文件变化上要比last-modified更加准确，优先级也更高。

**缓存策略选择流程图**

[点击查看有缓存情况下的流程图](https://www.processon.com/view/link/5d53c473e4b0ac2b6178cdab)

步骤
1、资源是否复用，也就是判断这个请求需要实施缓存策略吗。no-store:不允许缓存响应，重新获取资源。
2、no-cache:启用缓存策略。private:只客户端缓存。public:代理服务器缓存。
3、然后通过max-age和s-maxage来判断资源是否过期。
4、至于协商缓存，请看下图

[点击查看缓存策略流程图](https://www.processon.com/view/link/5d53b7b5e4b0ac2b6178a405)

最为关键的一环主要ETag和Last-modified的区分，还有就是对于响应结果是200还是304的区分。


###### 获取缓存资源的几种方式
- Service Worker
  运行在浏览器背后的独立线程，如果要使用，传输协议必须为HTTPS，因为Service Worker中涉及到请求拦截，使用HTTPS协议来保障安全。
- Memory Cache
  所指是内存中的缓存，既然是内存中，优先级还是比较高的，所以浏览器会优先考虑将资源存储在内存中，响应速度也是很快的，但并不是所有资源都能够存储到内存中，一般图片以及部分HTML、CSS、JSS会存储，由于内存空间有限，很多比较大的文件还是直接存储硬盘。具体原理还是根据不同的浏览器来定夺。而且**Memory Cache会随着进程的结束而释放**。
- Disk Cache
  存储在硬盘上的缓存，对比Memmory Cache存储容量要大，存储时效也更长。而且相同地址的资源如果被缓存下来，即使是跨站点，也能共同使用。
- Push Cache
  1、属于HTTP/2中的特性，
  2、Edge和Safari兼容性一般。
  3、可以推送no-cache和no-store的资源
  4、会话阶段的缓存，当 session 终止时，缓存也随之释放。


>如果大佬您想继续探讨或者学习更多知识，欢迎去这篇文章的github上提issues,也欢迎加入QQ或者微信一起探讨：854280588![QQ.png](https://upload-images.jianshu.io/upload_images/9590646-b7730844fa9df19d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)![微信](https://upload-images.jianshu.io/upload_images/9590646-d529498c10973856.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
